{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting setup\n",
    "I'm setting up infrastructure to backtest machine learning models. Initially, the models predict the price of certain markets, with the same model trained on all markets. Investment model is very simple based on the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantiacsToolbox\n",
    "from quantiacsToolbox import loadData\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, ensemble, metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA PREP\n",
    "def fillnans(inArr):\n",
    "    ''' fills in (column-wise)value gaps with the most recent non-nan value.\n",
    "    fills in value gaps with the most recent non-nan value.\n",
    "    Leading nan's remain in place. The gaps are filled in only after the first non-nan entry.\n",
    "    Args:\n",
    "        inArr (list, numpy array)\n",
    "    Returns:\n",
    "        returns an array of the same size as inArr with the nan-values replaced by the most recent non-nan entry.\n",
    "    '''\n",
    "    inArr = inArr.astype(float)\n",
    "    nanPos = np.where(np.isnan(inArr))\n",
    "    nanRow = nanPos[0]\n",
    "    nanCol = nanPos[1]\n",
    "    myArr = inArr.copy()\n",
    "    for i in range(len(nanRow)):\n",
    "        if nanRow[i] > 0:\n",
    "            myArr[nanRow[i], nanCol[i]] = myArr[nanRow[i] - 1, nanCol[i]]\n",
    "    return myArr\n",
    "\n",
    "def mySettings(lookback = 200):\n",
    "    \"\"\" Define your trading system settings here \"\"\"\n",
    "\n",
    "    settings = {}\n",
    "\n",
    "    # Futures Contracts\n",
    "    settings['markets'] = ['CASH', 'F_AD', 'F_BO', 'F_BP', 'F_C', 'F_CC', 'F_CD',\n",
    "                           'F_CL', 'F_CT', 'F_DX', 'F_EC', 'F_ED', 'F_ES', 'F_FC', 'F_FV', 'F_GC',\n",
    "                           'F_HG', 'F_HO', 'F_JY', 'F_KC', 'F_LB', 'F_LC', 'F_LN', 'F_MD', 'F_MP',\n",
    "                           'F_NG', 'F_NQ', 'F_NR', 'F_O', 'F_OJ', 'F_PA', 'F_PL', 'F_RB', 'F_RU',\n",
    "                           'F_S', 'F_SB', 'F_SF', 'F_SI', 'F_SM', 'F_TU', 'F_TY', 'F_US', 'F_W', 'F_XX',\n",
    "                           'F_YM']\n",
    "\n",
    "    \n",
    "    settings['budget'] = 10 ** 6\n",
    "    settings['slippage'] = 0.05\n",
    "\n",
    "    settings['threshold'] = 0.2\n",
    "    \n",
    "    # Train, Val, Test time ranges\n",
    "    settings['train_start'] = '20100601'\n",
    "    settings['train_end'] = '20120101'\n",
    "    settings['val_start'] = '20120101'#settings['train_end']\n",
    "    settings['val_end'] = '20140101'\n",
    "#     settings['test_start'] = settings['val_end']\n",
    "#     settings['test_end'] = '20140101'\n",
    "    # Lookback is how much historical data to pull for each day\n",
    "    settings['lookback'] = lookback\n",
    "    \n",
    "    return settings\n",
    "\n",
    "def generate_returns_dict(quant_dict,col='CLOSE'):\n",
    "    '''Generate daily returns column based on daily price column col, handle NaNs.\n",
    "    Input is quant_dict, dictionary returned from loadData function.'''\n",
    "    \n",
    "    quant_dict['RET'] = generate_returns(quant_dict['CLOSE'],quant_dict['RINFO'])\n",
    "\n",
    "    return quant_dict\n",
    "\n",
    "def generate_returns(CLOSE,RINFO):\n",
    "    RET = np.zeros([1,CLOSE.shape[1]])\n",
    "    RET = np.append(RET,np.float64(CLOSE[1:, :] - \\\n",
    "                    CLOSE[:-1, :] - RINFO[1:, :]) / CLOSE[:-1, :],axis=0)\n",
    "    RET = fillnans(RET)\n",
    "    RET[np.isnan(RET)] = 0\n",
    "    return RET\n",
    "\n",
    "def quant_dict_to_df(quant_dict,settings):\n",
    "    '''Function transforms quant_dict returned from loadData function (plus returns)\n",
    "    into dataframe. Each row in dataframe is a day for a particular market.'''\n",
    "\n",
    "    # MARKET and DATE must be in col_list\n",
    "    if 'markets' not in list(settings.keys()):\n",
    "        print(\"MARKET must be in col_list\")\n",
    "        return\n",
    "    if 'DATE' not in list(quant_dict.keys()):\n",
    "        print(\"MARKET must be in col_list\")\n",
    "        return\n",
    "\n",
    "    # Set up df by market and date\n",
    "    df = pd.DataFrame([[m,d] for m in settings['markets'] for d in quant_dict['DATE']],columns=['MARKET','DATE'])\n",
    "\n",
    "    # Flatten out the data and append columns\n",
    "\n",
    "    for col in quant_dict.keys():\n",
    "        if col != 'DATE':\n",
    "            # Fillnans with zero for now\n",
    "            quant_dict[col][np.isnan(quant_dict[col])] = 0\n",
    "            df[col] = quant_dict[col].flatten('F')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FEATURE GENERATION\n",
    "\n",
    "\n",
    "## MODEL EVALUATION\n",
    "def eval_model(reg, X_train, X_val, y_train, y_val, \n",
    "               metric_dict, binary_list, metric_df = None):\n",
    "    '''eval_model() generates train and val evaluation metrics for reg\n",
    "    regression model.\n",
    "    Inputs:\n",
    "    reg - Pre-trained regression model \n",
    "    X_train, X_val - Feature Dataframes\n",
    "    y_train, y_val - Returns to predict\n",
    "    metric_dict - Dictionary of metrics to calculate\n",
    "    binary_list - List of metrics that operate on sign(y)\n",
    "    metrif_df - optional, if provided then metrics for reg will be appended\n",
    "    \n",
    "    Outputs:\n",
    "    metric_df - DataFrame w/ rows of metric_list and columns train and val\n",
    "    '''\n",
    "    # Predictions\n",
    "    y_train_pred = reg.predict(X_train)\n",
    "    y_val_pred = reg.predict(X_val)\n",
    "\n",
    "    # Define the empty metrics dataframe (if not provided)\n",
    "    if metric_df is None:\n",
    "        df_ix = [a+b for b in ['_train','_val'] for a in metric_dict]\n",
    "        metric_df = pd.DataFrame(index=df_ix)\n",
    "    \n",
    "    # Metrics calculation loop\n",
    "    reg_name = str(reg)[:15]\n",
    "    for met in metric_dict:\n",
    "        if met in binary_list:\n",
    "            metric_df.loc[met+'_train',reg_name] = metric_dict[met]( \\\n",
    "                          np.sign(y_train),np.sign(y_train_pred))\n",
    "            metric_df.loc[met+'_val',reg_name] = metric_dict[met]( \\\n",
    "                          np.sign(y_val),np.sign(y_val_pred))\n",
    "        else:\n",
    "            metric_df.loc[met+'_train',reg_name] = metric_dict[met]( \\\n",
    "                          y_train,y_train_pred)\n",
    "            metric_df.loc[met+'_val',reg_name] = metric_dict[met]( \\\n",
    "                          y_val,y_val_pred)\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Settings\n",
    "settings = mySettings()\n",
    "dataToLoad = set(['DATE', 'OPEN', 'HIGH', 'LOW', 'CLOSE', 'P', 'RINFO'])\n",
    "\n",
    "# Train, Val, and Test\n",
    "train_dict = loadData(marketList=settings['markets'], dataToLoad=dataToLoad, refresh=False, \n",
    "                    beginInSample=settings['train_start'], endInSample=settings['train_end'],\n",
    "             dataDir=\"../tickerData\")\n",
    "val_dict = loadData(marketList=settings['markets'], dataToLoad=dataToLoad, refresh=False, \n",
    "                    beginInSample=settings['val_start'], endInSample=settings['val_end'],\n",
    "             dataDir=\"../tickerData\")\n",
    "# test_dict = loadData(marketList=settings['markets'], dataToLoad=dataToLoad, refresh=False, \n",
    "#                     beginInSample=settings['test_start'], endInSample=settings['test_end'],\n",
    "#              dataDir=\"../tickerData\")\n",
    "\n",
    "train_dict = generate_returns_dict(train_dict)\n",
    "# train_df = quant_dict_to_df(train_dict,settings)\n",
    "\n",
    "val_dict = generate_returns_dict(val_dict)\n",
    "# val_df = quant_dict_to_df(val_dict,settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAG\n",
    "def lag(RETURNS,lag):\n",
    "    '''lag returns a pd.Series of the lagged values in col, and the df with the lag column appended. \n",
    "       First #(lag) rows are zeroes (may change this later to remove these columns)'''\n",
    "\n",
    "    out = np.zeros([lag,RETURNS.shape[1]])\n",
    "    out = np.append(out, RETURNS[:-lag,:],axis=0)\n",
    "    return out\n",
    "\n",
    "def lag_feats(RETURNS, lag_list, remove_rows=True):\n",
    "    '''lag_feats generates lag features, as defined by lag_list, \n",
    "    and removes initial rows that do not have previous information for lag.\n",
    "    Output is a list of arrays with RETURNS.shape.'''\n",
    "    # Add lag columns\n",
    "    out_list = []\n",
    "    for l in lag_list:\n",
    "        out_list.append(lag(RETURNS,l))\n",
    "    if remove_rows:\n",
    "        # Remove the first max_lag rows from each list\n",
    "        max_lag = np.max(lag_list)\n",
    "        for i,ll in enumerate(out_list):\n",
    "            out_list[i] = ll[max_lag:]            \n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate returns\n",
    "# lag_list = [1,2,3,4,5,10,20,50]\n",
    "lag_list = [1,2,3,5,10,25,50,100,150,200]\n",
    "train_dict['LAG_LIST'] = lag_feats(train_dict['RET'], lag_list, False)\n",
    "val_dict['LAG_LIST'] = lag_feats(val_dict['RET'], lag_list, False)\n",
    "\n",
    "num_feats = len(lag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_lag_features(data_dict,num_feats=num_feats):\n",
    "    '''This function reshapes data_dict into X and y, accounting for lags.\n",
    "    Should eventually be expanded to hangle other features.'''\n",
    "    \n",
    "    max_lag = np.max(lag_list)\n",
    "\n",
    "    # Create X and y\n",
    "    y = data_dict['RET'][max_lag:,:].flatten('F')\n",
    "    full_lag_arr = np.array(data_dict['LAG_LIST'])\n",
    "    print(\"full lag arr shape: \",full_lag_arr.shape)\n",
    "    # Remove early returns that don't have lag\n",
    "    lag_arr = full_lag_arr[:,max_lag:,:]\n",
    "\n",
    "    # Reshape for model\n",
    "    lag_arr = lag_arr.reshape((lag_arr.shape[0],-1),order='F').T\n",
    "    y = y.reshape(-1,order='F')\n",
    "\n",
    "    return lag_arr, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shape_lag_features(train_dict)\n",
    "X_val, y_val = shape_lag_features(val_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fit the model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Dictionary of metrics to calculate\n",
    "metric_dict = {\"r2\": metrics.r2_score,\n",
    "               \"MSE\": metrics.mean_squared_error,\n",
    "               \"Accuracy\": metrics.accuracy_score}\n",
    "# List of metrics that operate on sign(y_pred)\n",
    "binary_list = ['Accuracy']\n",
    "\n",
    "metric_df = eval_model(reg, X_train, X_val, y_train, y_val, \n",
    "               metric_dict, binary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = ensemble.RandomForestRegressor()\n",
    "reg2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = eval_model(reg2, X_train, X_val, y_train, y_val, \n",
    "               metric_dict, binary_list, metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "pdtabulate=lambda df:tabulate(df,headers='keys',tablefmt='psql')\n",
    "print(pdtabulate(metric_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,20])\n",
    "plt.plot(y_val)\n",
    "y_val_pred = reg.predict(X_val)\n",
    "plt.plot(y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myStrategy(object):\n",
    "\n",
    "    def myTradingSystem(self, DATE, OPEN, HIGH, LOW, CLOSE, VOL, OI, P, R, RINFO, exposure, equity, settings):\n",
    "        \n",
    "        # Get parameters from setting\n",
    "        nMarkets = len(settings['markets'])\n",
    "        lookback = settings['lookback']\n",
    "        threshold = settings['threshold']\n",
    "\n",
    "#         pos = np.zeros(nMarkets, dtype=np.float)\n",
    "        \n",
    "        # Generate features for a single day\n",
    "        # Returns\n",
    "        RETURNS = generate_returns(CLOSE,RINFO)\n",
    "        # Lags\n",
    "        lag_list = [1,2,3,5,10,25,50,100,150,200]\n",
    "        LAG_LIST = lag_feats(RETURNS, lag_list, False)\n",
    "        # Keep only the last day\n",
    "        X = np.array(LAG_LIST)[:,-1,:].T\n",
    "\n",
    "        reg = settings['model']\n",
    "        try:\n",
    "            trend = reg.predict(X)\n",
    "            # Threshold\n",
    "            trend = (abs(trend) > threshold)*trend\n",
    "\n",
    "            pos = np.sign(trend)\n",
    "\n",
    "        # for NaN data set position to 0\n",
    "        except ValueError:\n",
    "            print(\"trend isnan\", np.isnan(trend).any())\n",
    "            print(\"pos isnan\", np.isnan(trend).any())\n",
    "            pos[market] = .0\n",
    "\n",
    "        return pos, settings\n",
    "    \n",
    "    def mySettings(self):\n",
    "        \"\"\" Define your trading system settings here \"\"\"\n",
    "\n",
    "        settings = {}\n",
    "\n",
    "        # Futures Contracts\n",
    "        settings['markets'] = ['CASH', 'F_AD', 'F_BO', 'F_BP', 'F_C', 'F_CC', 'F_CD',\n",
    "                               'F_CL', 'F_CT', 'F_DX', 'F_EC', 'F_ED', 'F_ES', 'F_FC', 'F_FV', 'F_GC',\n",
    "                               'F_HG', 'F_HO', 'F_JY', 'F_KC', 'F_LB', 'F_LC', 'F_LN', 'F_MD', 'F_MP',\n",
    "                               'F_NG', 'F_NQ', 'F_NR', 'F_O', 'F_OJ', 'F_PA', 'F_PL', 'F_RB', 'F_RU',\n",
    "                               'F_S', 'F_SB', 'F_SF', 'F_SI', 'F_SM', 'F_TU', 'F_TY', 'F_US', 'F_W', 'F_XX',\n",
    "                               'F_YM']\n",
    "\n",
    "        settings['budget'] = 10 ** 6\n",
    "        settings['slippage'] = 0.05\n",
    "\n",
    "        settings['threshold'] = 1e-5\n",
    "\n",
    "        # Train, Val, Test time ranges\n",
    "        settings['train_start'] = '20100601'\n",
    "        settings['train_end'] = '20120101'\n",
    "        settings['val_start'] = '20120101'#settings['train_end']\n",
    "        settings['val_end'] = '20140101'\n",
    "\n",
    "        settings['beginInSample'] = settings['val_end']\n",
    "        settings['endInSample'] = '20160101'\n",
    "        # Lookback is how much historical data to pull for each day\n",
    "        settings['lookback'] = 200\n",
    "        \n",
    "        settings['model'] = reg2\n",
    "        \n",
    "        return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.errstate(invalid='ignore', divide='ignore'):\n",
    "    result = quantiacsToolbox.runts(myStrategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(np.array([1,2,3,np.NaN])).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
